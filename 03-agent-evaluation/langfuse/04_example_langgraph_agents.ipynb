{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"Jupyter Notebook\" title: \"Example - Trace and Evaluate LangGraph Agents\" description: \"This guide shows how to evaluate LangGraph Agents with Langfuse using online and offline evaluation methods.\" category: \"Integrations\" -->\n",
    "\n",
    "# LangGraph 代理追踪与评估完整指南\n",
    "\n",
    "## 📖 教程概述\n",
    "\n",
    "在本教程中，我们将深入学习如何使用 [Langfuse](https://langfuse.com)（一个强大的大模型可观测性平台）与 [Hugging Face Datasets](https://huggingface.co/datasets)，来**全面监控 [LangGraph 代理](https://github.com/langchain-ai/langgraph) 的执行过程（traces）**并**科学评估其性能表现**。\n",
    "\n",
    "## 🎯 学习目标\n",
    "\n",
    "本指南将帮助您掌握将 AI 代理快速且可靠地部署到生产环境所需的核心技能：\n",
    "- **在线评估**：实时监控生产环境中的代理表现\n",
    "- **离线评估**：使用基准数据集进行系统性测试\n",
    "\n",
    "💡 **延伸阅读**：想了解更多 LLM 评估策略和最佳实践，请参阅我们的[详细博文](https://langfuse.com/blog/2025-03-04-llm-evaluation-101-best-practices-and-challenges)。\n",
    "\n",
    "## 🔍 为什么 AI 代理评估如此重要？\n",
    "\n",
    "在 AI 代理开发过程中，评估是确保系统质量的关键环节：\n",
    "\n",
    "- **🐛 问题诊断**：当代理任务执行失败或结果不理想时，能够快速定位问题根源\n",
    "- **📊 性能监控**：实时追踪系统的成本消耗、响应延迟等关键指标\n",
    "- **🔄 持续改进**：通过用户反馈和评估数据，不断提升代理的可靠性与安全性\n",
    "- **🚀 生产就绪**：确保代理在真实环境中能够稳定运行\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzPbsmLrfoSN"
   },
   "source": [
    "## 🛠️ 步骤 0：环境准备与依赖安装\n",
    "\n",
    "### 📦 安装核心依赖库\n",
    "\n",
    "在开始本教程之前，我们需要安装以下核心库：\n",
    "\n",
    "- **`langgraph`**：用于构建多节点、状态驱动的 AI 代理工作流\n",
    "- **`langfuse`**：提供大模型应用的可观测性和评估功能  \n",
    "- **`langchain`** 系列：用于 LLM 应用开发的核心框架\n",
    "- **`datasets`**：Hugging Face 的数据集处理库\n",
    "\n",
    "```bash\n",
    "# 安装命令将在下方代码单元格中执行\n",
    "```\n",
    "\n",
    "<!-- CALLOUT_START type: \"info\" emoji: \"⚠️\" -->\n",
    "**📌 重要提示：** \n",
    "- 本教程使用 **Langfuse Python SDK v3**，它提供了更好的性能和新特性\n",
    "- 如果您仍在使用 Python SDK v2，请参考我们的[旧版 LangGraph 集成指南](https://github.com/langfuse/langfuse-docs/blob/662509b3296daddcddb292f14b10a62e7c39407d/pages/docs/integrations/langchain/example-langgraph-agents.md#L4)进行升级\n",
    "- 建议在虚拟环境中运行本教程以避免依赖冲突\n",
    "<!-- CALLOUT_END -->\n",
    "\n",
    "### 🔧 环境要求\n",
    "\n",
    "- **Python 版本**：3.8 或更高版本\n",
    "- **操作系统**：支持 Windows、macOS、Linux\n",
    "- **网络**：需要访问 OpenAI API 和 Langfuse 服务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "_EI_0ZfzfoSO",
    "outputId": "44309e31-7737-45d5-a530-00ea7ac18f52"
   },
   "outputs": [],
   "source": [
    "# 📦 安装所需的Python包\n",
    "# 使用魔法命令 %pip 在Jupyter环境中安装依赖库\n",
    "\n",
    "%pip install langfuse langchain langgraph langchain_openai langchain_community langchain_huggingface\n",
    "\n",
    "# 各库功能说明：\n",
    "# - langfuse: LLM应用的可观测性和评估平台\n",
    "# - langchain: 大语言模型应用开发框架\n",
    "# - langgraph: 基于langchain的图形化工作流构建工具  \n",
    "# - langchain_openai: OpenAI模型的langchain集成\n",
    "# - langchain_community: 社区贡献的langchain扩展\n",
    "# - langchain_huggingface: Hugging Face模型的langchain集成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHRsxz1VfoSP"
   },
   "source": [
    "## 🔑 步骤 1：配置 API 密钥和环境变量\n",
    "\n",
    "### 获取 Langfuse API 密钥\n",
    "\n",
    "在开始使用 Langfuse 之前，您需要获取 API 访问凭证：\n",
    "\n",
    "#### 方案一：使用 Langfuse Cloud（推荐）\n",
    "1. 访问 [Langfuse Cloud](https://cloud.langfuse.com) 并注册账户\n",
    "2. 创建新项目或选择现有项目\n",
    "3. 在项目设置页面获取以下密钥：\n",
    "   - `LANGFUSE_PUBLIC_KEY`：以 `pk-lf-` 开头的公钥\n",
    "   - `LANGFUSE_SECRET_KEY`：以 `sk-lf-` 开头的私钥\n",
    "\n",
    "#### 方案二：自托管 Langfuse\n",
    "如果您选择自托管部署，请按照 [Langfuse 自托管文档](https://langfuse.com/docs/deployment/self-host) 进行配置。\n",
    "\n",
    "### 获取 OpenAI API 密钥\n",
    "\n",
    "1. 访问 [OpenAI 平台](https://platform.openai.com/)\n",
    "2. 注册账户并完成身份验证\n",
    "3. 在 API 密钥页面创建新的 API 密钥\n",
    "4. 确保账户有足够的余额用于 API 调用\n",
    "\n",
    "### 🔐 安全提醒\n",
    "\n",
    "- **请勿将 API 密钥硬编码在代码中**\n",
    "- **生产环境建议使用环境变量或密钥管理系统**\n",
    "- **定期轮换密钥以提高安全性** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZnxtWx9foSP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 🔑 配置 Langfuse API 凭证\n",
    "# 从项目设置页面获取密钥：https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\"  # 替换为您的公钥\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\"  # 替换为您的私钥\n",
    "\n",
    "# 🌍 设置 Langfuse 服务器地址\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\"  # 🇪🇺 欧洲区域\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\"  # 🇺🇸 美国区域（可选）\n",
    "\n",
    "# 🤖 配置 OpenAI API 密钥\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"  # 替换为您的 OpenAI API 密钥\n",
    "\n",
    "# 💡 提示：在生产环境中，建议通过以下方式设置环境变量：\n",
    "# 1. 使用 .env 文件配合 python-dotenv 库\n",
    "# 2. 在操作系统层面设置环境变量\n",
    "# 3. 使用云平台的密钥管理服务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"Jupyter Notebook\" title: \"Example - Trace and Evaluate LangGraph Agents\" description: \"This guide shows how to evaluate LangGraph Agents with Langfuse using online and offline evaluation methods.\" category: \"Integrations\" -->\n",
    "\n",
    "# LangGraph 代理追踪与评估完整指南\n",
    "\n",
    "## 📖 教程概述\n",
    "\n",
    "在本教程中，我们将深入学习如何使用 [Langfuse](https://langfuse.com)（一个强大的大模型可观测性平台）与 [Hugging Face Datasets](https://huggingface.co/datasets)，来**全面监控 [LangGraph 代理](https://github.com/langchain-ai/langgraph) 的执行过程（traces）**并**科学评估其性能表现**。\n",
    "\n",
    "## 🎯 学习目标\n",
    "\n",
    "本指南将帮助您掌握将 AI 代理快速且可靠地部署到生产环境所需的核心技能：\n",
    "- **在线评估**：实时监控生产环境中的代理表现\n",
    "- **离线评估**：使用基准数据集进行系统性测试\n",
    "\n",
    "💡 **延伸阅读**：想了解更多 LLM 评估策略和最佳实践，请参阅我们的[详细博文](https://langfuse.com/blog/2025-03-04-llm-evaluation-101-best-practices-and-challenges)。\n",
    "\n",
    "## 🔍 为什么 AI 代理评估如此重要？\n",
    "\n",
    "在 AI 代理开发过程中，评估是确保系统质量的关键环节：\n",
    "\n",
    "- **🐛 问题诊断**：当代理任务执行失败或结果不理想时，能够快速定位问题根源\n",
    "- **📊 性能监控**：实时追踪系统的成本消耗、响应延迟等关键指标\n",
    "- **🔄 持续改进**：通过用户反馈和评估数据，不断提升代理的可靠性与安全性\n",
    "- **🚀 生产就绪**：确保代理在真实环境中能够稳定运行\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"Jupyter Notebook\" title: \"Example - Trace and Evaluate LangGraph Agents\" description: \"This guide shows how to evaluate LangGraph Agents with Langfuse using online and offline evaluation methods.\" category: \"Integrations\" -->\n",
    "\n",
    "# LangGraph 代理追踪与评估完整指南\n",
    "\n",
    "## 📖 教程概述\n",
    "\n",
    "在本教程中，我们将深入学习如何使用 [Langfuse](https://langfuse.com)（一个强大的大模型可观测性平台）与 [Hugging Face Datasets](https://huggingface.co/datasets)，来**全面监控 [LangGraph 代理](https://github.com/langchain-ai/langgraph) 的执行过程（traces）**并**科学评估其性能表现**。\n",
    "\n",
    "## 🎯 学习目标\n",
    "\n",
    "本指南将帮助您掌握将 AI 代理快速且可靠地部署到生产环境所需的核心技能：\n",
    "- **在线评估**：实时监控生产环境中的代理表现\n",
    "- **离线评估**：使用基准数据集进行系统性测试\n",
    "\n",
    "💡 **延伸阅读**：想了解更多 LLM 评估策略和最佳实践，请参阅我们的[详细博文](https://langfuse.com/blog/2025-03-04-llm-evaluation-101-best-practices-and-challenges)。\n",
    "\n",
    "## 🔍 为什么 AI 代理评估如此重要？\n",
    "\n",
    "在 AI 代理开发过程中，评估是确保系统质量的关键环节：\n",
    "\n",
    "- **🐛 问题诊断**：当代理任务执行失败或结果不理想时，能够快速定位问题根源\n",
    "- **📊 性能监控**：实时追踪系统的成本消耗、响应延迟等关键指标\n",
    "- **🔄 持续改进**：通过用户反馈和评估数据，不断提升代理的可靠性与安全性\n",
    "- **🚀 生产就绪**：确保代理在真实环境中能够稳定运行\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"Jupyter Notebook\" title: \"Example - Trace and Evaluate LangGraph Agents\" description: \"This guide shows how to evaluate LangGraph Agents with Langfuse using online and offline evaluation methods.\" category: \"Integrations\" -->\n",
    "\n",
    "# LangGraph 代理追踪与评估完整指南\n",
    "\n",
    "## 📖 教程概述\n",
    "\n",
    "在本教程中，我们将深入学习如何使用 [Langfuse](https://langfuse.com)（一个强大的大模型可观测性平台）与 [Hugging Face Datasets](https://huggingface.co/datasets)，来**全面监控 [LangGraph 代理](https://github.com/langchain-ai/langgraph) 的执行过程（traces）**并**科学评估其性能表现**。\n",
    "\n",
    "## 🎯 学习目标\n",
    "\n",
    "本指南将帮助您掌握将 AI 代理快速且可靠地部署到生产环境所需的核心技能：\n",
    "- **在线评估**：实时监控生产环境中的代理表现\n",
    "- **离线评估**：使用基准数据集进行系统性测试\n",
    "\n",
    "💡 **延伸阅读**：想了解更多 LLM 评估策略和最佳实践，请参阅我们的[详细博文](https://langfuse.com/blog/2025-03-04-llm-evaluation-101-best-practices-and-challenges)。\n",
    "\n",
    "## 🔍 为什么 AI 代理评估如此重要？\n",
    "\n",
    "在 AI 代理开发过程中，评估是确保系统质量的关键环节：\n",
    "\n",
    "- **🐛 问题诊断**：当代理任务执行失败或结果不理想时，能够快速定位问题根源\n",
    "- **📊 性能监控**：实时追踪系统的成本消耗、响应延迟等关键指标\n",
    "- **🔄 持续改进**：通过用户反馈和评估数据，不断提升代理的可靠性与安全性\n",
    "- **🚀 生产就绪**：确保代理在真实环境中能够稳定运行\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"Jupyter Notebook\" title: \"Example - Trace and Evaluate LangGraph Agents\" description: \"This guide shows how to evaluate LangGraph Agents with Langfuse using online and offline evaluation methods.\" category: \"Integrations\" -->\n",
    "\n",
    "# LangGraph 代理追踪与评估完整指南\n",
    "\n",
    "## 📖 教程概述\n",
    "\n",
    "在本教程中，我们将深入学习如何使用 [Langfuse](https://langfuse.com)（一个强大的大模型可观测性平台）与 [Hugging Face Datasets](https://huggingface.co/datasets)，来**全面监控 [LangGraph 代理](https://github.com/langchain-ai/langgraph) 的执行过程（traces）**并**科学评估其性能表现**。\n",
    "\n",
    "## 🎯 学习目标\n",
    "\n",
    "本指南将帮助您掌握将 AI 代理快速且可靠地部署到生产环境所需的核心技能：\n",
    "- **在线评估**：实时监控生产环境中的代理表现\n",
    "- **离线评估**：使用基准数据集进行系统性测试\n",
    "\n",
    "💡 **延伸阅读**：想了解更多 LLM 评估策略和最佳实践，请参阅我们的[详细博文](https://langfuse.com/blog/2025-03-04-llm-evaluation-101-best-practices-and-challenges)。\n",
    "\n",
    "## 🔍 为什么 AI 代理评估如此重要？\n",
    "\n",
    "在 AI 代理开发过程中，评估是确保系统质量的关键环节：\n",
    "\n",
    "- **🐛 问题诊断**：当代理任务执行失败或结果不理想时，能够快速定位问题根源\n",
    "- **📊 性能监控**：实时追踪系统的成本消耗、响应延迟等关键指标\n",
    "- **🔄 持续改进**：通过用户反馈和评估数据，不断提升代理的可靠性与安全性\n",
    "- **🚀 生产就绪**：确保代理在真实环境中能够稳定运行\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"Jupyter Notebook\" title: \"Example - Trace and Evaluate LangGraph Agents\" description: \"This guide shows how to evaluate LangGraph Agents with Langfuse using online and offline evaluation methods.\" category: \"Integrations\" -->\n",
    "\n",
    "# LangGraph 代理追踪与评估完整指南\n",
    "\n",
    "## 📖 教程概述\n",
    "\n",
    "在本教程中，我们将深入学习如何使用 [Langfuse](https://langfuse.com)（一个强大的大模型可观测性平台）与 [Hugging Face Datasets](https://huggingface.co/datasets)，来**全面监控 [LangGraph 代理](https://github.com/langchain-ai/langgraph) 的执行过程（traces）**并**科学评估其性能表现**。\n",
    "\n",
    "## 🎯 学习目标\n",
    "\n",
    "本指南将帮助您掌握将 AI 代理快速且可靠地部署到生产环境所需的核心技能：\n",
    "- **在线评估**：实时监控生产环境中的代理表现\n",
    "- **离线评估**：使用基准数据集进行系统性测试\n",
    "\n",
    "💡 **延伸阅读**：想了解更多 LLM 评估策略和最佳实践，请参阅我们的[详细博文](https://langfuse.com/blog/2025-03-04-llm-evaluation-101-best-practices-and-challenges)。\n",
    "\n",
    "## 🔍 为什么 AI 代理评估如此重要？\n",
    "\n",
    "在 AI 代理开发过程中，评估是确保系统质量的关键环节：\n",
    "\n",
    "- **🐛 问题诊断**：当代理任务执行失败或结果不理想时，能够快速定位问题根源\n",
    "- **📊 性能监控**：实时追踪系统的成本消耗、响应延迟等关键指标\n",
    "- **🔄 持续改进**：通过用户反馈和评估数据，不断提升代理的可靠性与安全性\n",
    "- **🚀 生产就绪**：确保代理在真实环境中能够稳定运行\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔗 连接验证与客户端初始化\n",
    "\n",
    "设置完环境变量后，我们需要初始化 Langfuse 客户端并验证连接。\n",
    "\n",
    "**核心概念解释：**\n",
    "- **`get_client()`**：Langfuse 提供的便捷函数，会自动读取环境变量中的凭证\n",
    "- **客户端实例**：用于与 Langfuse 服务器通信的对象\n",
    "- **连接验证**：确保 API 密钥正确且网络连接正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📡 导入 Langfuse 客户端并建立连接\n",
    "from langfuse import get_client\n",
    " \n",
    "# 🔧 初始化 Langfuse 客户端\n",
    "# get_client() 会自动从环境变量中读取 API 凭证\n",
    "langfuse = get_client()\n",
    " \n",
    "# ✅ 验证 API 连接和身份认证\n",
    "# auth_check() 方法会测试与 Langfuse 服务器的连接\n",
    "if langfuse.auth_check():\n",
    "    print(\"✅ Langfuse 客户端连接成功！API 认证通过\")\n",
    "    print(\"🎯 现在可以开始追踪和评估 LLM 应用了\")\n",
    "else:\n",
    "    print(\"❌ 认证失败！请检查以下项目：\")\n",
    "    print(\"   1. API 密钥是否正确设置\")\n",
    "    print(\"   2. 服务器地址是否正确\")\n",
    "    print(\"   3. 网络连接是否正常\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uulS5iGHfoSP"
   },
   "source": [
    "## 🧪 步骤 2：构建第一个 LangGraph 代理并验证追踪功能\n",
    "\n",
    "### 💡 什么是追踪（Tracing）？\n",
    "\n",
    "在 LLM 应用开发中，**追踪（Tracing）**是指记录应用程序执行过程中的详细信息：\n",
    "- **执行路径**：代理执行了哪些步骤\n",
    "- **性能指标**：每个步骤的耗时、令牌消耗等\n",
    "- **输入输出**：每个环节的输入和输出内容\n",
    "- **错误信息**：出现问题时的详细错误日志\n",
    "\n",
    "### 🎯 本节目标\n",
    "\n",
    "我们将创建一个简单的问答代理来验证 Langfuse 追踪功能是否正常工作。\n",
    "\n",
    "**技术要点：**\n",
    "- 使用 **LangGraph** 构建状态驱动的代理工作流\n",
    "- 通过 **CallbackHandler** 实现自动追踪\n",
    "- 在 Langfuse 仪表板中查看执行记录\n",
    "\n",
    "🔍 **运行成功标志**：如果配置正确，您将在 [Langfuse 追踪仪表板](https://cloud.langfuse.com/traces) 中看到详细的执行日志和性能指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcyynS9CfoSP",
    "outputId": "5e8eb8c2-bcff-4149-ff8b-21d706c1d25b"
   },
   "outputs": [],
   "source": [
    "# 🚀 构建简单的 LangGraph 问答代理\n",
    "\n",
    "# 📦 导入必要的类型和工具\n",
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 🔧 定义代理的状态结构\n",
    "class State(TypedDict):\n",
    "    # messages 字段存储对话历史，类型为列表\n",
    "    # Annotated[list, add_messages] 定义了状态更新的方式：\n",
    "    # - list: 数据类型为列表\n",
    "    # - add_messages: 更新时追加消息而不是覆盖（保持对话历史）\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 🏗️ 创建状态图构建器\n",
    "# StateGraph 是 LangGraph 的核心类，用于构建状态驱动的工作流\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 🤖 初始化 OpenAI 语言模型\n",
    "# - model: 使用 GPT-4o 模型（性能强大且成本适中）\n",
    "# - temperature: 设置为 0.2，输出相对稳定但保持一定创造性\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "# 💬 定义聊天机器人节点函数\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    聊天机器人的核心逻辑\n",
    "    \n",
    "    参数:\n",
    "        state: 当前的对话状态，包含消息历史\n",
    "        \n",
    "    返回:\n",
    "        包含新消息的字典，会被自动合并到状态中\n",
    "    \"\"\"\n",
    "    # 调用 LLM 处理当前所有消息，并返回回复\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 🔗 构建工作流图结构\n",
    "# 1. 添加节点：每个节点代表一个工作单元（通常是 Python 函数）\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 2. 设置入口点：告诉图从哪个节点开始执行\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "# 3. 设置结束点：定义工作流的终止条件\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "# ⚙️ 编译图以获得可执行的代理\n",
    "# compile() 方法将图定义转换为可运行的 CompiledGraph 对象\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "print(\"✅ 简单问答代理构建完成！\")\n",
    "print(\"🔧 代理架构：输入 → ChatBot节点 → 输出\")\n",
    "print(\"📝 支持功能：基本问答、上下文理解\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 启用 Langfuse 追踪并运行代理\n",
    "\n",
    "# 📡 导入 Langfuse 的 LangChain 回调处理器\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# 🎯 初始化 Langfuse 追踪处理器\n",
    "# CallbackHandler 会自动捕获 LangChain/LangGraph 的执行信息\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "print(\"🚀 开始运行代理并启用 Langfuse 追踪...\")\n",
    "print(\"❓ 用户问题：What is Langfuse?\")\n",
    "print(\"📊 追踪信息将发送到 Langfuse 平台\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 🏃 运行代理并启用追踪\n",
    "# stream() 方法允许实时接收代理的执行结果\n",
    "for step_result in graph.stream(\n",
    "    # 输入：包含用户消息的状态\n",
    "    {\"messages\": [HumanMessage(content=\"What is Langfuse?\")]},\n",
    "    # 配置：启用 Langfuse 回调处理器进行追踪\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    "):\n",
    "    print(f\"📥 代理执行步骤: {step_result}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"✅ 代理执行完成！\")\n",
    "print(\"🔗 请访问 Langfuse 仪表板查看详细追踪信息\")\n",
    "print(\"📍 链接: https://cloud.langfuse.com/traces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPLt1hRkfoSQ"
   },
   "source": [
    "### 🔍 验证追踪功能：查看 Langfuse 仪表板\n",
    "\n",
    "#### 📊 如何检查追踪记录\n",
    "\n",
    "运行上述代码后，请按以下步骤验证追踪功能：\n",
    "\n",
    "1. **访问仪表板**：打开 [Langfuse 追踪仪表板](https://cloud.langfuse.com/traces)\n",
    "2. **查找记录**：在追踪列表中找到刚才的执行记录\n",
    "3. **分析数据**：点击记录查看详细的执行信息\n",
    "\n",
    "#### 🔬 追踪记录包含什么信息？\n",
    "\n",
    "在 Langfuse 中，您将看到以下重要信息：\n",
    "\n",
    "- **📝 Spans（跨度）**：每个执行步骤的详细记录\n",
    "- **📋 Logs（日志）**：执行过程中的日志信息  \n",
    "- **⏱️ 时间戳**：每个步骤的精确执行时间\n",
    "- **💰 成本信息**：API 调用的令牌消耗和费用\n",
    "- **📊 性能指标**：延迟、吞吐量等关键指标\n",
    "\n",
    "#### 📸 Langfuse 中的示例追踪截图\n",
    "\n",
    "![Langfuse 中的示例追踪](https://langfuse.com/images/cookbook/example-langgraph-evaluation/first-example-trace.png)\n",
    "\n",
    "💡 **小提示**：追踪记录可能需要几秒钟才能在仪表板中显示，请稍作等待。\n",
    "\n",
    "🔗 _[查看示例追踪记录](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/ed0970b5-b251-4b85-9023-c0ed81462510?timestamp=2025-03-20T13%3A44%3A44.381Z&display=details&observation=0731595f-06e4-4f5a-b535-6e09677a752d)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onjMD-ZJfoSQ"
   },
   "source": [
    "## 🔬 步骤 3：构建并观测复杂的邮件处理代理\n",
    "\n",
    "### 🎯 进阶实战：真实业务场景模拟\n",
    "\n",
    "既然已确认基础追踪功能有效，现在我们来构建一个更加复杂且贴近实际业务场景的代理系统。\n",
    "\n",
    "### 📧 业务场景：智能邮件管理助手\n",
    "\n",
    "我们将创建一个模拟 **蝙蝠侠管家阿尔弗雷德** 的邮件处理代理，具备以下功能：\n",
    "\n",
    "#### 🔧 核心功能模块\n",
    "- **📬 邮件接收**：读取和解析邮件内容\n",
    "- **🔍 垃圾邮件识别**：智能判断邮件是否为垃圾邮件\n",
    "- **🗂️ 自动分类**：对合法邮件进行分类处理\n",
    "- **✍️ 回复起草**：为重要邮件生成回复草稿\n",
    "- **📢 通知主人**：向韦恩先生汇报重要邮件\n",
    "\n",
    "#### 📊 追踪的高级指标\n",
    "\n",
    "通过这个复杂代理，我们将观察以下关键指标：\n",
    "- **💰 成本追踪**：详细的令牌消耗和 API 费用\n",
    "- **⏱️ 性能分析**：每个处理步骤的耗时分布\n",
    "- **🔄 工作流路径**：代理的决策逻辑和执行路径\n",
    "- **❌ 错误监控**：异常情况的捕获和分析\n",
    "\n",
    "### 🏗️ 技术架构特点\n",
    "\n",
    "- **状态驱动**：使用 LangGraph 的状态管理机制\n",
    "- **条件分支**：根据邮件类型执行不同的处理逻辑\n",
    "- **多节点协作**：模拟真实的业务处理流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 导入构建复杂代理所需的库\n",
    "\n",
    "import os  # 操作系统接口，用于环境变量管理\n",
    "from typing import TypedDict, List, Dict, Any, Optional  # 类型注解，提高代码可读性和IDE支持\n",
    "from langgraph.graph import StateGraph, START, END  # LangGraph核心组件：状态图、开始节点、结束节点\n",
    "from langchain_openai import ChatOpenAI  # OpenAI模型的LangChain集成\n",
    "from langchain_core.messages import HumanMessage  # LangChain消息类型\n",
    "\n",
    "print(\"📚 库导入完成，准备构建邮件处理代理...\")\n",
    "print(\"🔧 即将使用的核心组件：\")\n",
    "print(\"   - StateGraph: 构建状态驱动的工作流\")\n",
    "print(\"   - ChatOpenAI: 调用 GPT 模型进行智能处理\")\n",
    "print(\"   - TypedDict: 定义严格的数据结构\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏗️ 定义邮件处理代理的状态结构\n",
    "\n",
    "class EmailState(TypedDict):\n",
    "    \"\"\"\n",
    "    邮件处理代理的状态数据结构\n",
    "    \n",
    "    这个类定义了代理在处理邮件过程中需要维护的所有状态信息\n",
    "    \"\"\"\n",
    "    # 📧 原始邮件信息\n",
    "    email: Dict[str, Any]  # 包含发件人、主题、正文等邮件完整信息\n",
    "    \n",
    "    # 🔍 垃圾邮件检测结果  \n",
    "    is_spam: Optional[bool]  # 是否为垃圾邮件（True/False/None）\n",
    "    spam_reason: Optional[str]  # 判定为垃圾邮件的原因说明\n",
    "    \n",
    "    # 🗂️ 邮件分类信息\n",
    "    email_category: Optional[str]  # 邮件类别（如：商务、个人、紧急等）\n",
    "    \n",
    "    # ✍️ 回复草稿\n",
    "    draft_response: Optional[str]  # 阿尔弗雷德为主人准备的回复草稿\n",
    "    \n",
    "    # 💬 对话历史记录\n",
    "    messages: List[Dict[str, Any]]  # 存储处理过程中的LLM对话记录\n",
    "\n",
    "print(\"✅ 邮件状态结构定义完成\")\n",
    "print(\"📋 状态字段说明：\")\n",
    "print(\"   - email: 原始邮件数据\")\n",
    "print(\"   - is_spam: 垃圾邮件判定结果\") \n",
    "print(\"   - draft_response: 回复草稿\")\n",
    "print(\"   - messages: LLM对话历史\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 初始化大语言模型（LLM），后续所有节点都会复用它进行推理\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# 🧱 在运行实际图之前再次定义状态结构，确保每个节点能拿到自己需要的数据\n",
    "class EmailState(TypedDict):\n",
    "    email: Dict[str, Any]            # 📬 当前待处理的原始邮件内容（发件人、主题、正文）\n",
    "    is_spam: Optional[bool]          # 🚨 垃圾邮件判定结果，None 表示尚未判定\n",
    "    draft_response: Optional[str]    # ✍️ Alfred 起草的回复内容\n",
    "    messages: List[Dict[str, Any]]   # 🗒️ LangChain 对话历史，用来记录模型调用\n",
    "\n",
    "# 🔁 定义工作流中的每个节点函数\n",
    "def read_email(state: EmailState):\n",
    "    \"\"\"\n",
    "    入口节点：展示邮件基础信息，帮助我们在命令行中观察流程。\n",
    "    \"\"\"\n",
    "    email = state[\"email\"]  # 从状态中取出当前邮件\n",
    "    print(f\"Alfred is processing an email from {email['sender']} with subject: {email['subject']}\")\n",
    "    return {}  # 节点只做展示，不修改状态\n",
    "\n",
    "def classify_email(state: EmailState):\n",
    "    \"\"\"\n",
    "    使用 LLM 判断当前邮件是否为垃圾邮件。\n",
    "    如果是垃圾邮件就不记录模型对话，避免污染历史。\n",
    "    \"\"\"\n",
    "    email = state[\"email\"]\n",
    "\n",
    "    # 构造提示词，向 LLM 传入邮件的所有关键信息\n",
    "    prompt = f\"\"\"\n",
    "As Alfred the butler of Mr wayne and it's SECRET identity Batman, analyze this email and determine if it is spam or legitimate and should be brought to Mr wayne's attention.\n",
    "\n",
    "Email:\n",
    "From: {email['sender']}\n",
    "Subject: {email['subject']}\n",
    "Body: {email['body']}\n",
    "\n",
    "First, determine if this email is spam.\n",
    "answer with SPAM or HAM if it's legitimate. Only return the answer\n",
    "Answer :\n",
    "    \"\"\"\n",
    "    messages = [HumanMessage(content=prompt)]  # LangChain 要求传入 HumanMessage 对象\n",
    "    response = model.invoke(messages)  # 调用 LLM 获得判定结果\n",
    "\n",
    "    response_text = response.content.lower()  # 统一转小写，便于关键词匹配\n",
    "    print(response_text)  # 在控制台输出，方便我们调试和观察\n",
    "    is_spam = \"spam\" in response_text and \"ham\" not in response_text  # 同时排除同时出现 spam/ham 的情况\n",
    "\n",
    "    if not is_spam:\n",
    "        # 如果不是垃圾邮件，就将本次问答追加到对话历史中，供后续节点使用\n",
    "        new_messages = state.get(\"messages\", []) + [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": response.content}\n",
    "        ]\n",
    "    else:\n",
    "        # 垃圾邮件无需记录上下文，保持原有的消息记录\n",
    "        new_messages = state.get(\"messages\", [])\n",
    "\n",
    "    return {\n",
    "        \"is_spam\": is_spam,       # 把垃圾邮件判定结果写回状态\n",
    "        \"messages\": new_messages  # 同步对话历史\n",
    "    }\n",
    "\n",
    "def handle_spam(state: EmailState):\n",
    "    \"\"\"\n",
    "    垃圾邮件分支：这里只演示打印提示语，真实项目可以写入数据库或报警。\n",
    "    \"\"\"\n",
    "    print(\"Alfred has marked the email as spam.\")\n",
    "    print(\"The email has been moved to the spam folder.\")\n",
    "    return {}  # 返回空字典表示不修改状态字段\n",
    "\n",
    "def drafting_response(state: EmailState):\n",
    "    \"\"\"\n",
    "    合法邮件分支：让 LLM 帮忙撰写一份礼貌的回复草稿。\n",
    "    \"\"\"\n",
    "    email = state[\"email\"]\n",
    "\n",
    "    # 维持提示词，明确输出语气和需要覆盖的关键内容\n",
    "    prompt = f\"\"\"\n",
    "As Alfred the butler, draft a polite preliminary response to this email.\n",
    "\n",
    "Email:\n",
    "From: {email['sender']}\n",
    "Subject: {email['subject']}\n",
    "Body: {email['body']}\n",
    "\n",
    "Draft a brief, professional response that Mr. Wayne can review and personalize before sending.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # 将最新的问答追加到对话历史里，保持上下文完整\n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"draft_response\": response.content,  # 保存生成的邮件草稿\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def notify_mr_wayne(state: EmailState):\n",
    "    \"\"\"\n",
    "    收尾节点：模拟向布鲁斯·韦恩汇报邮件处理结果。\n",
    "    \"\"\"\n",
    "    email = state[\"email\"]\n",
    "\n",
    "    print(\"\n",
    "\" + \"=\"*50)\n",
    "    print(f\"Sir, you've received an email from {email['sender']}.\")\n",
    "    print(f\"Subject: {email['subject']}\")\n",
    "    print(\"\n",
    "I've prepared a draft response for your review:\")\n",
    "    print(\"-\"*50)\n",
    "    print(state[\"draft_response\"])\n",
    "    print(\"=\"*50 + \"\n",
    "\")\n",
    "\n",
    "    return {}\n",
    "\n",
    "# 🧭 路由逻辑：根据垃圾邮件判定选择下一步的分支\n",
    "def route_email(state: EmailState) -> str:\n",
    "    if state[\"is_spam\"]:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"legitimate\"\n",
    "\n",
    "# 🛠️ 创建状态图，将上面定义的节点串联成一个 LangGraph 工作流\n",
    "email_graph = StateGraph(EmailState)\n",
    "\n",
    "# 📌 注册节点——每一行都会把函数变成图里的一个执行节点\n",
    "email_graph.add_node(\"read_email\", read_email)  # 首先读取并展示邮件信息\n",
    "email_graph.add_node(\"classify_email\", classify_email)  # 然后请 LLM 判定垃圾邮件\n",
    "email_graph.add_node(\"handle_spam\", handle_spam)  # 垃圾邮件走单独的处理分支\n",
    "email_graph.add_node(\"drafting_response\", drafting_response)  # 合法邮件生成回复草稿\n",
    "email_graph.add_node(\"notify_mr_wayne\", notify_mr_wayne)  # 最后向主人汇报结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ➕ 配置节点之间的流转顺序\n",
    "email_graph.add_edge(START, \"read_email\")  # 图的起点先进入 read_email 节点\n",
    "\n",
    "# 🧠 判定之后根据结果流向不同分支\n",
    "email_graph.add_edge(\"read_email\", \"classify_email\")  # 展示完邮件后调用分类逻辑\n",
    "\n",
    "# 🔀 添加条件分支：route_email 返回字符串决定下一条边\n",
    "email_graph.add_conditional_edges(\n",
    "    \"classify_email\",  # 根据垃圾邮件判定结果来决定去向\n",
    "    route_email,\n",
    "    {\n",
    "        \"spam\": \"handle_spam\",          # 判定为垃圾邮件则直接走 handle_spam 节点\n",
    "        \"legitimate\": \"drafting_response\"  # 合法邮件则继续撰写回复\n",
    "    }\n",
    ")\n",
    "\n",
    "# ✅ 收尾：无论哪个分支走完都回到 END 节点\n",
    "email_graph.add_edge(\"handle_spam\", END)  # 垃圾邮件处理完毕即结束\n",
    "email_graph.add_edge(\"drafting_response\", \"notify_mr_wayne\")  # 回复草稿后通知主人\n",
    "email_graph.add_edge(\"notify_mr_wayne\", END)  # 汇报结束后整个流程收尾\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧮 将图结构编译成可执行的 LangGraph 代理对象\n",
    "compiled_graph = email_graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📨 准备两封示例邮件，帮助我们观察不同分支的执行效果\n",
    "legitimate_email = {\n",
    "    \"sender\": \"Joker\",  # 发件人\n",
    "    \"subject\": \"Found you Batman ! \",  # 邮件主题\n",
    "    \"body\": \"Mr. Wayne,I found your secret identity ! I know you're batman ! Ther's no denying it, I have proof of that and I'm coming to find you soon. I'll get my revenge. JOKER\"  # 邮件正文\n",
    "}\n",
    "\n",
    "spam_email = {\n",
    "    \"sender\": \"Crypto bro\",  # 垃圾邮件常见的推销者\n",
    "    \"subject\": \"The best investment of 2025\",  # 诱导性标题\n",
    "    \"body\": \"Mr Wayne, I just launched an ALT coin and want you to buy some !\"  # 明显的垃圾推广\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# 🧩 初始化 Langfuse 的回调处理器，用于自动记录执行轨迹\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# ✅ 运行合法邮件示例，演示完整工作流\n",
    "print(\"\n",
    "Processing legitimate email...\")\n",
    "legitimate_result = compiled_graph.invoke(\n",
    "    input={\n",
    "        \"email\": legitimate_email,\n",
    "        \"is_spam\": None,\n",
    "        \"draft_response\": None,\n",
    "        \"messages\": []\n",
    "        },\n",
    "    config={\"callbacks\": [langfuse_handler]}  # 将回调挂到图的执行配置上\n",
    ")\n",
    "\n",
    "# 🚨 再运行垃圾邮件示例，观察分支差异\n",
    "print(\"\n",
    "Processing spam email...\")\n",
    "spam_result = compiled_graph.invoke(\n",
    "    input={\n",
    "        \"email\": spam_email,\n",
    "        \"is_spam\": None,\n",
    "        \"draft_response\": None,\n",
    "        \"messages\": []\n",
    "        },\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjkhTgLWfoSQ"
   },
   "source": [
    "### 追踪结构\n",
    "\n",
    "Langfuse 会记录包含若干 **span（跨度）** 的**trace（追踪）**，每个 span 代表代理逻辑中的一个步骤。本例中的追踪包含整体运行以及如下子跨度：\n",
    "- 工具调用（get_weather）\n",
    "- LLM 调用（使用 'gpt-4o' 的 Responses API）\n",
    "\n",
    "你可以检查这些记录以精确了解时间消耗、令牌使用量等：\n",
    "\n",
    "![Langfuse 中的追踪树](https://langfuse.com/images/cookbook/example-langgraph-evaluation/trace-tree.png)\n",
    "\n",
    "_[前往该追踪](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/3dd76e4b-980c-40eb-ae6d-ba9db5f6a349?timestamp=2025-03-20T14%3A56%3A16.665Z&display=details&observation=22b11054-93a8-4ff9-b862-babfcee906ec)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHZAkQuefoSQ"
   },
   "source": [
    "## 在线评估\n",
    "\n",
    "在线评估指在真实线上环境（生产环境的实际使用中）对代理进行评估。这需要对真实用户交互进行持续监控与结果分析。\n",
    "\n",
    "我们在此总结了多种评估技术的指南：[链接](https://langfuse.com/blog/2025-03-04-llm-evaluation-101-best-practices-and-challenges)。\n",
    "\n",
    "### 生产环境常见监控指标\n",
    "\n",
    "1. **成本（Costs）**：埋点会记录令牌用量，你可按每个令牌的价格估算成本。\n",
    "2. **延迟（Latency）**：观察完成每个步骤或整次运行所需的时间。\n",
    "3. **用户反馈（User Feedback）**：用户可直接提供反馈（如点赞/点踩）以帮助迭代与修正代理。\n",
    "4. **LLM 评审（LLM-as-a-Judge）**：使用额外的 LLM 近实时评估代理输出（如检测毒性或正确性）。\n",
    "\n",
    "下面展示这些指标的示例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHMvJ1QlfoSQ"
   },
   "source": [
    "#### 1. 成本（Costs）\n",
    "\n",
    "下图展示了 `gpt-4o` 调用的用量，可据此识别高成本步骤并优化代理。\n",
    "\n",
    "![成本](https://langfuse.com/images/cookbook/example-langgraph-evaluation/gpt-4o-costs.png)\n",
    "\n",
    "_[前往该追踪](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/3dd76e4b-980c-40eb-ae6d-ba9db5f6a349?timestamp=2025-03-20T14%3A56%3A16.665Z&display=details&observation=22b11054-93a8-4ff9-b862-babfcee906ec)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz0y9mn7foSQ"
   },
   "source": [
    "#### 2. 延迟（Latency）\n",
    "\n",
    "还可以查看完成每个步骤所需的时间。如下例所示，整个运行约 3 秒，你可以细分到各步骤。此举有助于识别瓶颈并优化代理。\n",
    "\n",
    "![延迟](https://langfuse.com/images/cookbook/example-langgraph-evaluation/agent-latency.png)\n",
    "\n",
    "_[前往该追踪](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/3dd76e4b-980c-40eb-ae6d-ba9db5f6a349?timestamp=2025-03-20T14%3A56%3A16.665Z&display=timeline)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtKiK62HfoSR"
   },
   "source": [
    "#### 3. 用户反馈（User Feedback）\n",
    "\n",
    "如果你的代理嵌入在用户界面中，可以采集用户的直接反馈（例如在聊天界面中的点赞/点踩）。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468,
     "referenced_widgets": [
      "8b10018448324153af2ee1f9bd83d140",
      "cebcce63ea37474ca10f1828105ca2e6",
      "9153dfceabff450ead31493c3c518d4c",
      "5a2b1d2255a34a7597b263755eaa14b3",
      "c8b3aa3aeec046ef8acfab640c2dee17",
      "ee1b1596e6ec42029fbf8b711c0fc41a",
      "ecd5521cdbc34eb7a866b4b2094fd500",
      "df007d6320cb4198a6dbf58485980394"
     ]
    },
    "id": "YI9siKKKfoSR",
    "outputId": "3eb086d0-4277-4cdd-966f-10b3c12272a6"
   },
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    "\n",
    "langfuse = get_client()\n",
    "\n",
    "# ✅ 方式一：使用上下文管理器返回的 span 对象给当前追踪打分\n",
    "with langfuse.start_as_current_span(\n",
    "    name=\"langgraph-request\") as span:\n",
    "    # ... 在这里执行具体的 LangGraph 逻辑 ...\n",
    "\n",
    "    # 直接对 span 调用 score_trace 并附加补充信息\n",
    "    span.score_trace(\n",
    "        name=\"user-feedback\",\n",
    "        value=1,\n",
    "        data_type=\"NUMERIC\",\n",
    "        comment=\"This was correct, thank you\"\n",
    "    )\n",
    "\n",
    "# ✅ 方式二：仍在上下文中时，可使用 score_current_trace 简化调用\n",
    "with langfuse.start_as_current_span(name=\"langgraph-request\") as span:\n",
    "    # ... LangGraph execution ...\n",
    "\n",
    "    # 使用当前上下文的 trace，而无需持有 span 对象\n",
    "    langfuse.score_current_trace(\n",
    "        name=\"user-feedback\",\n",
    "        value=1,\n",
    "        data_type=\"NUMERIC\"\n",
    "    )\n",
    "\n",
    "# ✅ 方式三：如果已经离开上下文，也可以通过 trace_id 进行补录\n",
    "langfuse.create_score(\n",
    "    trace_id=\"predefined-trace-id\",  # ⚠️ 这里需要替换成真实的 trace_id\n",
    "    name=\"user-feedback\",\n",
    "    value=1,\n",
    "    data_type=\"NUMERIC\",\n",
    "    comment=\"This was correct, thank you\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiemuS7YfoSR"
   },
   "source": [
    "用户反馈随后会被 Langfuse 捕获：\n",
    "\n",
    "![Langfuse 中捕获的用户反馈](https://langfuse.com/images/cookbook/example-langgraph-evaluation/user-feedback.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29KsI9xcfoSR"
   },
   "source": [
    "#### 4. 自动化的 LLM 评审打分（LLM-as-a-Judge）\n",
    "\n",
    "LLM-as-a-Judge 提供了一种自动评估代理输出的方法。你可以配置一个独立的 LLM 调用，用于评估输出的正确性、毒性、风格或其他你关心的指标。\n",
    "\n",
    "**工作流程：**\n",
    "1. 定义一个**评估模板**，例如“检查文本是否含有毒性”。\n",
    "2. 指定用于评审的模型（judge-model），例如 `gpt-4o-mini`。\n",
    "2. 每当代理生成输出时，将其与模板一起传给“评审”LLM。\n",
    "3. 评审 LLM 给出评分或标签，并将结果记录到可观测性平台。\n",
    "\n",
    "Langfuse 示例：\n",
    "\n",
    "![LLM 评审模板](https://langfuse.com/images/cookbook/integration_openai-agents/evaluator-template.png)\n",
    "![LLM 评审器](https://langfuse.com/images/cookbook/integration_openai-agents/evaluator.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UGGlYrB7foSR",
    "outputId": "3e2d7d06-a5be-4552-9f17-88d93dd7b600"
   },
   "outputs": [],
   "source": [
    "# 🔁 如果需要单独再次验证垃圾邮件路径，可以复用下面的调用代码\n",
    "print(\"\n",
    "Processing spam email...\")\n",
    "spam_result = compiled_graph.invoke(\n",
    "    input={\n",
    "        \"email\": spam_email,\n",
    "        \"is_spam\": None,\n",
    "        \"draft_response\": None,\n",
    "        \"messages\": []\n",
    "        },\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ") \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "处理垃圾邮件中...\n",
    "阿尔弗雷德正在处理来自 Crypto bro 的邮件，主题：The best investment of 2025\n",
    "spam\n",
    "阿尔弗雷德已将该邮件标记为垃圾邮件。\n",
    "该邮件已被移动到垃圾邮件文件夹。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Izr-3LiQfoSR"
   },
   "source": [
    "可以看到，该示例的答案被评审为“无毒性（not toxic）”。\n",
    "\n",
    "![LLM 评审得分示例](https://langfuse.com/images/cookbook/example-langgraph-evaluation/llm-as-a-judge-score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7fN0UTkfoSR"
   },
   "source": [
    "#### 5. 可观测性指标总览\n",
    "\n",
    "所有上述指标都可以在统一的仪表盘中可视化。这样你可以快速查看代理在多次会话中的表现，并随时间跟踪质量指标。\n",
    "\n",
    "![可观测性指标总览](https://langfuse.com/images/cookbook/integration_openai-agents/dashboard-dark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlwltgEkfoSR"
   },
   "source": [
    "## Offline Evaluation\n",
    "\n",
    "Online evaluation is essential for live feedback, but you also need **offline evaluation**—systematic checks before or during development. This helps maintain quality and reliability before rolling changes into production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5R8eNQxfoSR"
   },
   "source": [
    "### Dataset Evaluation\n",
    "\n",
    "In offline evaluation, you typically:\n",
    "1. Have a benchmark dataset (with prompt and expected output pairs)\n",
    "2. Run your agent on that dataset\n",
    "3. Compare outputs to the expected results or use an additional scoring mechanism\n",
    "\n",
    "Below, we demonstrate this approach with the [q&a-dataset](https://huggingface.co/datasets/junzhang1207/search-dataset), which contains questions and expected answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 📥 从 Hugging Face 下载示例数据集，这里包含问答形式的条目\n",
    "dataset = load_dataset(\"junzhang1207/search-dataset\", split=\"train\")\n",
    "df = pd.DataFrame(dataset)  # 转成 DataFrame 方便筛选与遍历\n",
    "print(\"First few rows of search-dataset:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们在 Langfuse 中创建一个数据集实体以追踪运行；随后将数据集中的每条记录添加到系统中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "langfuse = Langfuse()\n",
    "\n",
    "langfuse_dataset_name = \"qa-dataset_langgraph-agent\"\n",
    "\n",
    "# 🗂️ 在 Langfuse 中创建一个新的数据集，用于存储评测样本\n",
    "langfuse.create_dataset(\n",
    "    name=langfuse_dataset_name,\n",
    "    description=\"q&a dataset uploaded from Hugging Face\",\n",
    "    metadata={\n",
    "        \"date\": \"2025-03-21\",\n",
    "        \"type\": \"benchmark\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 仅选取 30 条示例数据上传，实际项目可根据需求调整\n",
    "df_30 = df.sample(30)\n",
    "\n",
    "for idx, row in df_30.iterrows():\n",
    "    langfuse.create_dataset_item(\n",
    "        dataset_name=langfuse_dataset_name,\n",
    "        input={\"text\": row[\"question\"]},            # Langfuse 需要明确的输入字段\n",
    "        expected_output={\"text\": row[\"expected_answer\"]}  # 提供标准答案便于后续评估\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Langfuse 中的数据集条目](https://langfuse.com/images/cookbook/example-langgraph-evaluation/example-dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在数据集上运行代理\n",
    "\n",
    "首先，构建一个使用 OpenAI 模型回答问题的简易 LangGraph 代理。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage  # 如需自定义输入消息可以使用该类型\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 🧱 定义状态结构：messages 字段会自动累积对话历史\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 🏗️ 初始化一个新的状态图构建器\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 🤖 准备要调用的 OpenAI 聊天模型\n",
    "llm = ChatOpenAI(model=\"gpt-4.5-preview\")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    单节点聊天机器人：\n",
    "    - 将当前所有消息传给 LLM\n",
    "    - 返回模型的回复，LangGraph 会自动把它追加到状态里\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# 🔗 注册节点与入口、出口\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "# ⚙️ compile() 会返回可直接调用的图实例\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define a helper function `my_agent()` that:\n",
    "1. Creates a Langfuse trace \n",
    "2. Fetches the `langfuse_handler_trace` to instrument the LangGraph execution. \n",
    "3. Runs our agent and passing `langfuse_handler_trace` to the invocation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langfuse import get_client\n",
    "from langfuse.langchain import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate  # 可用于自定义提示模板（本示例暂未使用）\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 🏗️ 构建一个带 Langfuse 追踪能力的 LangGraph 代理\n",
    "graph_builder = StateGraph(State)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")  # 选择对话模型\n",
    "langfuse = get_client()  # 复用前面配置好的 Langfuse 客户端\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    核心节点：将对话历史交给 LLM，并把生成结果包装成 LangGraph 需要的格式。\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "def my_agent(question, langfuse_handler):\n",
    "    \"\"\"\n",
    "    对外暴露的便捷函数：\n",
    "    1. 打开一个 Langfuse span 以便观测这次请求；\n",
    "    2. 调用 LangGraph 代理获取回答；\n",
    "    3. 将输入输出写回 Langfuse，方便后续评估。\n",
    "    \"\"\"\n",
    "\n",
    "    # 创建一个顶层追踪 span，所有上下文都会记录在这里\n",
    "    with langfuse.start_as_current_span(name=\"my-langgraph-agent\") as root_span:\n",
    "\n",
    "        # Step 2: LangChain processing\n",
    "        response = graph.invoke(\n",
    "            input={\"messages\": [HumanMessage(content=question)]},\n",
    "            config={\"callbacks\": [langfuse_handler]}\n",
    "        )\n",
    "\n",
    "        # 将原始问题和模型回答同步到 Langfuse 仪表盘\n",
    "        root_span.update_trace(\n",
    "            input=question,\n",
    "            output=response[\"messages\"][1].content)\n",
    "\n",
    "        print(question)\n",
    "        print(response[\"messages\"][1].content)\n",
    "\n",
    "    return response[\"messages\"][1].content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we loop over each dataset item, run the agent, and link the trace to the dataset item. We can also attach a quick evaluation score if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# 📡 初始化追踪组件：CallbackHandler 会把 LangChain 的每一步同步到 Langfuse\n",
    "langfuse_handler = CallbackHandler()\n",
    "langfuse = get_client()\n",
    "\n",
    "dataset = langfuse.get_dataset('qa-dataset_langgraph-agent')  # 获取上一步创建的数据集\n",
    "\n",
    "for item in dataset.items:\n",
    "    # ✅ item.run() 会为每个样本开启一个子追踪，方便查看单条样本的执行情况\n",
    "    with item.run(\n",
    "        run_name=\"run_gpt-4o\",\n",
    "        run_description=\"My first run\",\n",
    "        run_metadata={\"model\": \"gpt-4o\"},\n",
    "    ) as root_span:\n",
    "        # 进入此上下文的所有调用都会自动关联到当前 dataset item\n",
    "\n",
    "        # 🎯 运行核心业务逻辑时，再开一个 generation 上下文记录单次模型调用\n",
    "        with langfuse.start_as_current_generation(\n",
    "            name=\"llm-call\",\n",
    "            model=\"gpt-4o\",\n",
    "            input=item.input\n",
    "        ) as generation:\n",
    "            # 用我们刚才封装的 my_agent 完成实际问答\n",
    "            output = my_agent(str(item.input), langfuse_handler)\n",
    "            generation.update(output=output)\n",
    "\n",
    "        # 📝 可选择对结果打分（例如人工点评或自动指标）\n",
    "        root_span.score_trace(\n",
    "            name=\"user-feedback\",\n",
    "            value=1,\n",
    "            comment=\"This is a comment\",  # 可记录评分原因，便于回溯\n",
    "        )\n",
    "\n",
    "# 🔚 所有调用结束后刷新客户端，确保缓冲区里的数据都被发送\n",
    "langfuse.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can repeat this process with different agent configurations such as:\n",
    "- Models (gpt-4o-mini, o1, etc.)\n",
    "- Prompts\n",
    "- Tools (search vs. no search)\n",
    "- Complexity of agent (multi agent vs single agent)\n",
    "\n",
    "Then compare them side-by-side in Langfuse. In this example, I did run the agent 3 times on the 30 dataset questions. For each run, I used a different OpenAI model. You can see that amount of correctly answered questions improves when using a larger model (as expected). The `correct_answer` score is created by an [LLM-as-a-Judge Evaluator](https://langfuse.com/docs/scores/model-based-evals) that is set up to judge the correctness of the question based on the sample answer given in the dataset.\n",
    "\n",
    "![Dataset run overview](https://langfuse.com/images/cookbook/example-langgraph-evaluation/dataset_runs.png)\n",
    "![Dataset run comparison](https://langfuse.com/images/cookbook/example-langgraph-evaluation/dataset-run-comparison.png)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07431a8d1a2044b6baebcef3242f41c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07f767145c7741bfb950cd983c757cc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f5356bc1d4a4e0f895fa9482bb06a7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_427363e7b1ce4c7387b93f2794bdedb4",
       "IPY_MODEL_690c3eb1f314478083b725bcb1d38a25",
       "IPY_MODEL_edc537f5b13348c6b831365930c0cf31"
      ],
      "layout": "IPY_MODEL_7f0d7cf658054c448668bebacd96a59d"
     }
    },
    "12b08dc8912c4bfc81c81524eabc7898": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15fa9808df56469db8cc623bd127ceae",
      "placeholder": "​",
      "style": "IPY_MODEL_8948024991964982ad058f199066cc55",
      "value": " 316k/316k [00:00&lt;00:00, 1.94MB/s]"
     }
    },
    "15fa9808df56469db8cc623bd127ceae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ef6f4bf46e24841916cc9c611c1498b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "27794498f97b40a6b4ef1f2e36bf317e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7928d3e09417467aaa74cb2c6cea32ca",
      "max": 2125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ef6f4bf46e24841916cc9c611c1498b",
      "value": 2125
     }
    },
    "2b4fb4ce8c71405d80da978589750950": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "33f6af1d99a9451a86e6e6690cec7e43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_722784d0cb184f02b5250c57829cfdc4",
       "IPY_MODEL_e98c3c9567334b69a46ab23cd378358e",
       "IPY_MODEL_f0c04648902343288b4248dbf5589d7b"
      ],
      "layout": "IPY_MODEL_b32d7f992f064016ab548a961569b632"
     }
    },
    "35fb6e8a89194653abcaa84f6da4f190": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07f767145c7741bfb950cd983c757cc7",
      "placeholder": "​",
      "style": "IPY_MODEL_b620b045db0242189200a99090ea6b9f",
      "value": " 2.12k/2.12k [00:00&lt;00:00, 37.6kB/s]"
     }
    },
    "427363e7b1ce4c7387b93f2794bdedb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71277158b5ec43c8aa0accb86b15952d",
      "placeholder": "​",
      "style": "IPY_MODEL_c6b284ea83ee4de0a6de5210067b4b6b",
      "value": "Generating train split: 100%"
     }
    },
    "57152a81a7a24410992ccce525f28af0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a2b1d2255a34a7597b263755eaa14b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "636090e9932f4ff6a76152c64c92347d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "690c3eb1f314478083b725bcb1d38a25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c248d2dba9484807bc53d23ece012644",
      "max": 934,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2b4fb4ce8c71405d80da978589750950",
      "value": 934
     }
    },
    "6b2cbe08ebad4df8bf9e4711d78920f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71277158b5ec43c8aa0accb86b15952d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "722784d0cb184f02b5250c57829cfdc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a95842a82d46492796b7d0fd45bb9795",
      "placeholder": "​",
      "style": "IPY_MODEL_9b33b4e7c6bb4a728f21258c10034066",
      "value": "data-samples.json: 100%"
     }
    },
    "7928d3e09417467aaa74cb2c6cea32ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "799212d16c814bd696d57d0cdd35d9c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f0d7cf658054c448668bebacd96a59d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8948024991964982ad058f199066cc55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b10018448324153af2ee1f9bd83d140": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cebcce63ea37474ca10f1828105ca2e6",
       "IPY_MODEL_9153dfceabff450ead31493c3c518d4c"
      ],
      "layout": "IPY_MODEL_5a2b1d2255a34a7597b263755eaa14b3"
     }
    },
    "9153dfceabff450ead31493c3c518d4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "👎",
      "disabled": false,
      "icon": "thumbs-down",
      "layout": "IPY_MODEL_ecd5521cdbc34eb7a866b4b2094fd500",
      "style": "IPY_MODEL_df007d6320cb4198a6dbf58485980394",
      "tooltip": ""
     }
    },
    "93572e5407ea443999d1da45280741f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b33b4e7c6bb4a728f21258c10034066": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e40a549b3094b3892de5159dfe935ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a049a1b305ed4660bc48f81fe1c6c0a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a95842a82d46492796b7d0fd45bb9795": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b32d7f992f064016ab548a961569b632": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b620b045db0242189200a99090ea6b9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bdb56cd2387e4e30a1bf82beecf481d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a049a1b305ed4660bc48f81fe1c6c0a7",
      "max": 316103,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e40a549b3094b3892de5159dfe935ff",
      "value": 316103
     }
    },
    "c248d2dba9484807bc53d23ece012644": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6b284ea83ee4de0a6de5210067b4b6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8b3aa3aeec046ef8acfab640c2dee17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cebcce63ea37474ca10f1828105ca2e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "👍",
      "disabled": false,
      "icon": "thumbs-up",
      "layout": "IPY_MODEL_c8b3aa3aeec046ef8acfab640c2dee17",
      "style": "IPY_MODEL_ee1b1596e6ec42029fbf8b711c0fc41a",
      "tooltip": ""
     }
    },
    "dbf84b0798e0432599453e370740acaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f05fbf51e518417ea66a24db7b0a472e",
       "IPY_MODEL_27794498f97b40a6b4ef1f2e36bf317e",
       "IPY_MODEL_35fb6e8a89194653abcaa84f6da4f190"
      ],
      "layout": "IPY_MODEL_93572e5407ea443999d1da45280741f7"
     }
    },
    "df007d6320cb4198a6dbf58485980394": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "e2941796709b4284aa3b6143b19e064e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e815dd583c3243efa5d3b57672519f74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e98c3c9567334b69a46ab23cd378358e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b2cbe08ebad4df8bf9e4711d78920f2",
      "max": 2479,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed53bc55a6da404bac64993433f78ccf",
      "value": 2479
     }
    },
    "ea5cea15ae5741418720f77d5879ecc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f8be1fdbe50649ebb614194c140e0d9a",
       "IPY_MODEL_bdb56cd2387e4e30a1bf82beecf481d1",
       "IPY_MODEL_12b08dc8912c4bfc81c81524eabc7898"
      ],
      "layout": "IPY_MODEL_57152a81a7a24410992ccce525f28af0"
     }
    },
    "ecd5521cdbc34eb7a866b4b2094fd500": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed53bc55a6da404bac64993433f78ccf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "edc537f5b13348c6b831365930c0cf31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07431a8d1a2044b6baebcef3242f41c5",
      "placeholder": "​",
      "style": "IPY_MODEL_e2941796709b4284aa3b6143b19e064e",
      "value": " 934/934 [00:00&lt;00:00, 33.25 examples/s]"
     }
    },
    "ee1b1596e6ec42029fbf8b711c0fc41a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "f05fbf51e518417ea66a24db7b0a472e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3574545791843998157f0a3176e0ded",
      "placeholder": "​",
      "style": "IPY_MODEL_636090e9932f4ff6a76152c64c92347d",
      "value": "README.md: 100%"
     }
    },
    "f0c04648902343288b4248dbf5589d7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f68c9919bd26417cb1f3950f121276e3",
      "placeholder": "​",
      "style": "IPY_MODEL_e815dd583c3243efa5d3b57672519f74",
      "value": " 2.48k/2.48k [00:00&lt;00:00, 58.3kB/s]"
     }
    },
    "f3574545791843998157f0a3176e0ded": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f68c9919bd26417cb1f3950f121276e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6935aa898f544d2b4051ee259ec9e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8be1fdbe50649ebb614194c140e0d9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_799212d16c814bd696d57d0cdd35d9c7",
      "placeholder": "​",
      "style": "IPY_MODEL_f6935aa898f544d2b4051ee259ec9e30",
      "value": "data.jsonl: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}